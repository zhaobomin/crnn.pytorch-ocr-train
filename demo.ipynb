{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "5529\n",
      "loading pretrained model from ./data/ocr-lstm.pth\n",
      "### CNN + RNN模型输出结果\n",
      "- input shape: torch.Size([1, 1, 32, 100])\n",
      "-  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 64, 32, 100])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 64, 32, 100])\n",
      "-  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ":  torch.Size([1, 64, 16, 50])\n",
      "-  Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 128, 16, 50])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 128, 16, 50])\n",
      "-  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ":  torch.Size([1, 128, 8, 25])\n",
      "-  Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 256, 8, 25])\n",
      "-  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ":  torch.Size([1, 256, 8, 25])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 256, 8, 25])\n",
      "-  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 256, 8, 25])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 256, 8, 25])\n",
      "-  MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      ":  torch.Size([1, 256, 4, 26])\n",
      "-  Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 512, 4, 26])\n",
      "-  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ":  torch.Size([1, 512, 4, 26])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 512, 4, 26])\n",
      "-  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ":  torch.Size([1, 512, 4, 26])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 512, 4, 26])\n",
      "-  MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      ":  torch.Size([1, 512, 2, 27])\n",
      "-  Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      ":  torch.Size([1, 512, 1, 26])\n",
      "-  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ":  torch.Size([1, 512, 1, 26])\n",
      "-  ReLU(inplace=True)\n",
      ":  torch.Size([1, 512, 1, 26])\n",
      "- squeeze(2)\n",
      ":  torch.Size([1, 512, 26])\n",
      "- permute(2, 0, 1)\n",
      ":  torch.Size([26, 1, 512])\n",
      "-  LSTM(512, 256, bidirectional=True)\n",
      ":  torch.Size([26, 1, 512])\n",
      "-  Linear(in_features=512, out_features=256, bias=True)\n",
      ":  torch.Size([26, 1, 256])\n",
      "-  LSTM(256, 256, bidirectional=True)\n",
      ":  torch.Size([26, 1, 512])\n",
      "-  Linear(in_features=512, out_features=5530, bias=True)\n",
      ":  torch.Size([26, 1, 5530])\n",
      "- max(2) torch.Size([26, 1])\n",
      "- view(-1) torch.Size([26])\n",
      "### 模型结果\n",
      "- raw_pred size: 26, sim_pred size: 9\n",
      "- decode result: a------v--a-i-l-a--bbll-e- => available           \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import dataset\n",
    "from PIL import Image\n",
    "import models.crnn as crnn\n",
    "\n",
    "model_path = './data/ocr-lstm.pth'\n",
    "img_path = './data/demo.png'\n",
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "print(len(alphabet))\n",
    "alphabet = utils.alphabetChinese\n",
    "#alphabet_cn = utils.alphabetChinese\n",
    "print(len(utils.alphabetChinese))\n",
    "\n",
    "model = crnn.CRNN(32, 1, len(alphabet)+1, 256)\n",
    "\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "print('loading pretrained model from %s' % model_path)\n",
    "\n",
    "#model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.load_weights(model_path)\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "\n",
    "transformer = dataset.resizeNormalize((100, 32))\n",
    "\n",
    "image = Image.open(img_path).convert('L')\n",
    "image = transformer(image)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    image = image.cuda()\n",
    "\n",
    "image = image.view(1, *image.size())\n",
    "image = Variable(image)\n",
    "\n",
    "\n",
    "### 分步骤拆解输出\n",
    "o = image\n",
    "print('### CNN + RNN模型输出结果')\n",
    "print('- input shape:', o.shape)\n",
    "for m in model.cnn.children():\n",
    "    o = m(o)\n",
    "    print(\"- \", m)\n",
    "    print(': ', o.shape)\n",
    "\n",
    "b, c, h, w = o.size()\n",
    "assert h == 1, \"the height of conv must be 1\"\n",
    "o = o.squeeze(2) # remove dim(2), h -> [N, 512, 26]\n",
    "print(\"- squeeze(2)\")\n",
    "print(': ', o.shape)\n",
    "\n",
    "o = o.permute(2, 0, 1)  # [w, b, c] => [26, N, 512]\n",
    "print(\"- permute(2, 0, 1)\")\n",
    "print(': ', o.shape)\n",
    "\n",
    "\n",
    "for m in model.rnn.children():\n",
    "    o, s = m.rnn(o)\n",
    "    print(\"- \", m.rnn)\n",
    "    print(': ', o.shape)\n",
    "    \n",
    "    o = m.embedding(o)\n",
    "    print(\"- \", m.embedding)\n",
    "    print(': ', o.shape)\n",
    "    \n",
    "preds = o\n",
    "\n",
    "# 直接model输出\n",
    "#model.eval()\n",
    "#preds = model(image)\n",
    "\n",
    "max_val, preds = preds.max(2)\n",
    "print('- max(2)', preds.shape)\n",
    "\n",
    "#preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "preds = preds.view(-1)\n",
    "print('- view(-1)', preds.shape)\n",
    "\n",
    "\n",
    "print('### 模型结果')\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)]))\n",
    "raw_pred = converter.decode(preds.data, preds_size.data, raw=True)\n",
    "sim_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "print('- raw_pred size: %d, sim_pred size: %d' %(len(raw_pred), len(sim_pred)))\n",
    "print('- decode result: %-20s => %-20s' % (raw_pred, sim_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Shape变化总结\n",
    "1. cnn input [N, 1, 32, 100] => output [N, 512, 1, 26]  \n",
    "2. w = input_w/4 + 1 + 1 - 1 = input_w/4 + 1,   h = input_h/16-1(最后输出必须为1)\n",
    "3. 默认input [w(100), h(32)] -> [w(26), h(1)]\n",
    "\n",
    "### CNN + RNN模型输出结果\n",
    "- input shape: torch.Size([1, 1, 32, 100])\n",
    "-  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 64, 32, 100])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 64, 32, 100])\n",
    "-  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    ":  torch.Size([1, 64, 16, 50])\n",
    "-  Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 128, 16, 50])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 128, 16, 50])\n",
    "-  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    ":  torch.Size([1, 128, 8, 25])\n",
    "-  Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 256, 8, 25])\n",
    "-  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ":  torch.Size([1, 256, 8, 25])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 256, 8, 25])\n",
    "-  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 256, 8, 25])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 256, 8, 25])\n",
    "-  MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
    ":  torch.Size([1, 256, 4, 26])\n",
    "-  Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 512, 4, 26])\n",
    "-  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ":  torch.Size([1, 512, 4, 26])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 512, 4, 26])\n",
    "-  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    ":  torch.Size([1, 512, 4, 26])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 512, 4, 26])\n",
    "-  MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
    ":  torch.Size([1, 512, 2, 27])\n",
    "-  Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
    ":  torch.Size([1, 512, 1, 26])\n",
    "-  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ":  torch.Size([1, 512, 1, 26])\n",
    "-  ReLU(inplace=True)\n",
    ":  torch.Size([1, 512, 1, 26])\n",
    "- squeeze(2)\n",
    ":  torch.Size([1, 512, 26])\n",
    "- permute(2, 0, 1)\n",
    ":  torch.Size([26, 1, 512])\n",
    "-  LSTM(512, 256, bidirectional=True)\n",
    ":  torch.Size([26, 1, 512])\n",
    "-  Linear(in_features=512, out_features=256, bias=True)\n",
    ":  torch.Size([26, 1, 256])\n",
    "-  LSTM(256, 256, bidirectional=True)\n",
    ":  torch.Size([26, 1, 512])\n",
    "-  Linear(in_features=512, out_features=37, bias=True)\n",
    ":  torch.Size([26, 1, 37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from ./data/ocr-lstm.pth\n",
      "(323, 83)\n",
      "self.rnn(conv) shape torch.Size([32, 1, 5530])\n",
      "### 模型结果\n",
      "- raw_pred size: 32, sim_pred size: 7\n",
      "- decode result: 实---------现---有----什---么---不---同 => 实现有什么不同             \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import dataset\n",
    "from PIL import Image\n",
    "import models.crnn as crnn\n",
    "\n",
    "model_path = './data/ocr-lstm.pth'\n",
    "img_path = './data/demo3.jpeg'\n",
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "alphabet = utils.alphabetChinese\n",
    "\n",
    "model = crnn.CRNN(32, 1, len(alphabet)+1, 256)\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "print('loading pretrained model from %s' % model_path)\n",
    "\n",
    "model.load_weights(model_path)\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = Image.open(img_path).convert('L')\n",
    "print(image.size)\n",
    "img_w = 32 * image.size[0] // image.size[1]\n",
    "#scale = image.size[10] * image.size[1]*1.0 / 32\n",
    "\n",
    "transformer = dataset.resizeNormalize((img_w, 32))\n",
    "image = transformer(image)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    image = image.cuda()\n",
    "\n",
    "image = image.view(1, *image.size())\n",
    "image = Variable(image)\n",
    "\n",
    "#model.eval()\n",
    "preds = model(image)\n",
    "\n",
    "max_val, preds = preds.max(2)\n",
    "preds = preds.view(-1)\n",
    "\n",
    "\n",
    "print('### 模型结果')\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)]))\n",
    "raw_pred = converter.decode(preds.data, preds_size.data, raw=True)\n",
    "sim_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "print('- raw_pred size: %d, sim_pred size: %d' %(len(raw_pred), len(sim_pred)))\n",
    "print('- decode result: %-20s => %-20s' % (raw_pred, sim_pred))\n",
    "\n",
    "torch.save( model.state_dict(), 'crnn_withlstm.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from ./data/crnn_lstm.pth\n",
      "(323, 83)\n",
      "self.rnn(conv) shape torch.Size([32, 1, 5530])\n",
      "### 模型结果\n",
      "- raw_pred size: 32, sim_pred size: 7\n",
      "- decode result: 实---------现---有----什---么---不---同 => 实现有什么不同             \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import dataset\n",
    "from PIL import Image\n",
    "import models.crnn as crnn\n",
    "\n",
    "model_path = './data/crnn_lstm.pth'\n",
    "img_path = './data/demo3.jpeg'\n",
    "alphabet = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "alphabet = utils.alphabetChinese\n",
    "\n",
    "model = crnn.CRNN(32, 1, len(alphabet)+1, 256)\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "print('loading pretrained model from %s' % model_path)\n",
    "\n",
    "model.load_weights(model_path)\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "\n",
    "image = Image.open(img_path).convert('L')\n",
    "print(image.size)\n",
    "img_w = 32 * image.size[0] // image.size[1]\n",
    "#scale = image.size[10] * image.size[1]*1.0 / 32\n",
    "\n",
    "transformer = dataset.resizeNormalize((img_w, 32))\n",
    "image = transformer(image)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    image = image.cuda()\n",
    "\n",
    "image = image.view(1, *image.size())\n",
    "image = Variable(image)\n",
    "\n",
    "preds = model(image)\n",
    "\n",
    "max_val, preds = preds.max(2)\n",
    "preds = preds.view(-1)\n",
    "\n",
    "\n",
    "print('### 模型结果')\n",
    "preds_size = Variable(torch.IntTensor([preds.size(0)]))\n",
    "raw_pred = converter.decode(preds.data, preds_size.data, raw=True)\n",
    "sim_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "print('- raw_pred size: %d, sim_pred size: %d' %(len(raw_pred), len(sim_pred)))\n",
    "print('- decode result: %-20s => %-20s' % (raw_pred, sim_pred))\n",
    "\n",
    "#torch.save( model.state_dict(), 'crnn_withlstm.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from ./data/crnn_lstm.pth\n",
      "image.shape: (72, 184, 3)\n",
      "image.T.shape: (184, 72, 3)\n",
      "size: (184, 72)\n",
      "(184, 72) 32 81\n",
      "### 模型结果\n",
      "- raw_pred size: 26, sim_pred size: 5\n",
      "- decode result: v-------a-------p--p----e- => vappe               \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import models.crnn as crnn\n",
    "import numpy as np\n",
    "\n",
    "model_path = './data/crnn_lstm.pth'\n",
    "#model_path = './data/netCRNN.pth'\n",
    "img_path = './data/demo5.jpeg'\n",
    "img_path = './data/demo.png'\n",
    "\n",
    "model = crnn.CRNN()\n",
    "print('loading pretrained model from %s' % model_path)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "image = Image.open(img_path).convert('L')\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.imread(img_path)[:,:,(2,1,0)]\n",
    "\n",
    "#image = image.T\n",
    "print(\"image.shape:\",image.shape)\n",
    "\n",
    "image = image.transpose(1,0,2)\n",
    "print(\"image.T.shape:\",image.shape)\n",
    "\n",
    "image = Image.fromarray(image).convert('L')\n",
    "image = image.rotate(90, expand = 1)\n",
    "print('size:',image.size)\n",
    "\n",
    "img_w = 32 * image.size[0] // image.size[1]\n",
    "\n",
    "print(image.size, 32, img_w)\n",
    "preds, raw_pred,sim_pred = model.predict(image)\n",
    "\n",
    "\n",
    "print('### 模型结果')\n",
    "print('- raw_pred size: %d, sim_pred size: %d' %(len(raw_pred), len(sim_pred)))\n",
    "print('- decode result: %-20s => %-20s' % (raw_pred, sim_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model from ./data/netCRNN_True.pth\n",
      "(63, 446)\n",
      "### 模型结果\n",
      "- raw_pred size: 26, sim_pred size: 7\n",
      "- decode result: 胡-------思--乱---想--的--后---果 => 胡思乱想的后果             \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import models.crnn as crnn\n",
    "import cv2\n",
    "\n",
    "model_path = './data/crnn_dense.pth'\n",
    "model_path = './data/netCRNN_True.pth'\n",
    "img_path = './data/demo6.jpeg'\n",
    "#img_path = './data/demo.png'\n",
    "\n",
    "model = crnn.CRNN(lstmFlag=True)\n",
    "print('loading pretrained model from %s' % model_path)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "image = Image.fromarray(cv2.imread(img_path)[:,:,(2,1,0)]).convert('L')\n",
    "\n",
    "#image = Image.open(img_path).convert('L')\n",
    "print(image.size)\n",
    "\n",
    "preds, raw_pred,sim_pred = model.predict(image)\n",
    "\n",
    "\n",
    "print('### 模型结果')\n",
    "print('- raw_pred size: %d, sim_pred size: %d' %(len(raw_pred), len(sim_pred)))\n",
    "print('- decode result: %-20s => %-20s' % (raw_pred, sim_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
